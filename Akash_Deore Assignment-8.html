<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Another Page</title>
</head>
<body>
    <p> <mark>Q8 .HTML tags like a can have certain attributes. The href attribute is 
        mandatory in the a tag. Additionally, it is possible to use the title attribute 
        which specifies a text that emerges when the mouse cursor is moved above a 
        link. This kind of text is called a tool tip. Modify the link that you created in the 
        previous exercise so that a tool tip says "This leads you to another page." when 
        the mouse cursor is over the link.
        </mark></p>
        <h1>Chat GPT</h1>
        <p>ChatGPT (Chat Generative Pre-trained Transformer) is a chatbot launched by OpenAI in November 2022. It is built on top of OpenAI's GPT-3 family of large language models, and is fine-tuned (an approach to transfer learning) with both supervised and reinforcement learning techniques 
            ChatGPT was launched as a prototype on November 30, 2022, and quickly garnered attention for its detailed responses and articulate answers across many domains of knowledge.
            Its uneven factual accuracy was identified as a significant drawback.[3] Following the release of ChatGPT, OpenAI was valued at US$29 billion.[4]
        </p>
        <p>ChatGPT was fine-tuned on top of GPT-3.5 using supervised learning as well as reinforcement learning.[5] Both approaches used human trainers to improve the model's performance. In the case of supervised learning, the model was provided with conversations in which the trainers played both sides: the user and the AI assistant. In the reinforcement step, human trainers first ranked responses that the model had created in a previous conversation. These rankings were used to create 'reward models' that the model was further fine-tuned on using several iterations of Proximal Policy Optimization (PPO).[6][7] Proximal Policy Optimization algorithms present a cost-effective benefit to trust region policy optimization algorithms; they negate many of the computationally expensive operations with faster performance.[8][9] The models were trained in collaboration with Microsoft on their Azure supercomputing infrastructure.

            In addition, OpenAI continues to gather data from ChatGPT users that could be used to further train and fine-tune ChatGPT. Users are allowed to upvote or downvote the responses they receive from ChatGPT; upon upvoting or downvoting, they can also fill out a text field with additional feedback.</p>
        <p> <h2 title="This Link Will Lead You To What is Data Science "> <a href="http://127.0.0.1:5501/Akash_Deore%20Assignment-7.html" target="_blank"> Click Here Information Of Full Stack Development</a></h2></p>
</body>
</html>